# youtube_listing
API to fetch latest videos sorted in reverse chronological order of their publishing date-time from YouTube for a given tag/search query in a paginated response

## create following folders and file before running
- database      // will contain all the files generated by database
- scraper
    - keys.txt  // store all the api keys, if they are provided by file 

## command to start cluster 
```sh
docker-compose up -d --build 
```

to check status
```sh
docker-compose ps
```

- cluster containers
	- nginx : container for network routing and load-balancing. 
	- api : web2py based APIs. Name of app = 'youtube_listing'
	- postgres : main database, set its credentials in compose file
	- scraper : python container which runs only a single script, it will call the youtube api evevry 30s for serach_keyword provided, and store result into database table.

## AIP details

1. HOME

```sh
http://localhost:8080/youtube_listing/listing/home
```
This is the page which contains top 50 latest results collected

2. LATEST LISTING

```sh
localhost:8080/youtube_listing/listing/latest_listing
```
This is the api to get latest listings collected by scraper.
Input variables:
- page_no: ith number of the page required, will be skipped if value is not provided  
- page_max: no of records per page, will be skipped if value is 0 or  not provided  
- limit_max: max number of result, default 10, will be ignored if page_no AND page_max is provided
- offset: number of result have to skip , default 10, will be ignored if page_no AND page_max is provided
- data_orient: orient used to make json, refer to https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html#pandas-dataframe-to-json
- return_sql: if the sql used is also required


3. SEARCH LISTING

```sh
localhost:8080/youtube_listing/listing/search_listing
```
This is the api to get filtered data. This requires keyword input.
Input variables:
- page_no: ith number of the page required, will be skipped if value is not provided  
- page_max: no of records per page, will be skipped if value is 0 or  not provided  
- limit_max: max number of result, default 10, will be ignored if page_no AND page_max is provided
- offset: number of result have to skip , default 10, will be ignored if page_no AND page_max is provided
- data_orient: orient used to make json, refer to https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html#pandas-dataframe-to-json
- return_sql: if the sql used is also required
- start_time and end_time: time to filter the search, in ISO format ("yyyy-MM-dd'T'HH:mm:ss.SS'Z'"
). Default is now - 7days to now.
- keyword: actual string it has to search for in title and description
